{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout,LSTM,Input,Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "import keras.backend as K\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import gensim\n",
    "\n",
    "wv = gensim.models.word2vec.Word2Vec.load(\"updated_google_corpus\")\n",
    "\n",
    "TESTING_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "#test_data = pd.read_csv(\"test.csv\")\n",
    "#test_data = test_data.drop(\"index\",axis=1)\n",
    "#data = pd.concat([train_data,test_data],sort=False)\n",
    "\n",
    "\n",
    "MAX_LENGTH = train_data[\"description\"].apply(lambda x:len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size=  3064993  words\n"
     ]
    }
   ],
   "source": [
    "words = list(wv.wv.vocab.keys())\n",
    "word_to_index, index_to_word = dict(),dict()\n",
    "for i,word in enumerate(words):\n",
    "    word_to_index[word]=i\n",
    "    index_to_word[i]=word\n",
    "print(\"vocabulary size= \",len(words),\" words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorise(words,wv_model,max_length):\n",
    "    words = words.lower().split()\n",
    "    vectors = [wv_model[word] for word in words]\n",
    "    return append_zeros(vectors,max_length)\n",
    "def append_zeros(words,max_length):\n",
    "    for i in range(max_length-len(words)):\n",
    "        words.append(np.zeros(300))\n",
    "    return np.array(words)\n",
    "\n",
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    X_indices = np.zeros((m, max_len),dtype=int)\n",
    "    \n",
    "    for i in range(m):\n",
    "        \n",
    "        sentence_words = X[i].split()\n",
    "        \n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            j = j+1\n",
    "                \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if TESTING_MODE:\n",
    "#     d = pd.get_dummies(train_data[[\"country\",\"region_1\",\"region_2\",\"province\",\"taster_name\",\"variety\"]])\n",
    "#     d[\"points\"]= train_data[\"points\"]\n",
    "#     d[\"id\"] = train_data['id']\n",
    "# else:\n",
    "#     d = pd.get_dummies(data[[\"country\",\"region_1\",\"region_2\",\"province\",\"taster_name\",\"variety\"]])\n",
    "#     d[\"points\"]= data[\"points\"]\n",
    "#     d[\"id\"] = data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= pd.DataFrame()\n",
    "d[\"id\"] = train_data['id']\n",
    "if TESTING_MODE:\n",
    "    #d[\"description_vectors\"] = train_data[\"description\"].apply(lambda words:vectorise(words,wv,MAX_LENGTH))\n",
    "    d[\"description\"] = train_data[\"description\"].apply(lambda x:x.lower())\n",
    "#     for i in range(300):\n",
    "#         d[\"vec_dim_\"+str(i)]=description_vecs.apply(lambda v:v[i])\n",
    "else:\n",
    "    #d[\"description_vectors\"] = train_data[\"description\"].apply(lambda words:np.array([wv[word.lower()] for word in words.split()]))\n",
    "    d[\"description\"] = data[\"description\"].apply(lambda x:x.lower())\n",
    "#     for i in range(300):\n",
    "#         d[\"vec_dim_\"+str(i)] = description_vecs.apply(lambda v:v[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING_MODE:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(d, train_data[\"price\"], test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "else:\n",
    "    X_train,y_train,X_test, y_test = d[:175000], data[\"price\"][:175000], d[175000:], data[\"price\"][175000:]\n",
    "    \n",
    "X_train = X_train.drop([\"id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array([X_train.values[i][0] for i in range(len(X_train.values))])\n",
    "# X_train.shape\n",
    "ids = X_test[\"id\"]\n",
    "X_test = X_test.drop([\"id\"],axis=1)\n",
    "X_train = sentences_to_indices(np.array(X_train.values[:,0]),word_to_index,MAX_LENGTH)\n",
    "X_test = sentences_to_indices(np.array(X_test.values[:,0]),word_to_index,MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 122500)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1\n",
    "    emb_dim = word_to_vec_map[\"hello\"].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "                                            \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "        \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable = False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(pretrained_embedding_layer(wv,word_to_index,input_shape=(MAX_LENGTH,300)))\n",
    "# model.add(LSTM(128,return_sequences=False))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation(\"relu\"))\n",
    "\n",
    "def deepLSTM(input_shape, dropout_prob,n_h):\n",
    "    input_data = Input(shape=input_shape)\n",
    "    embedding_layer = pretrained_embedding_layer(wv,word_to_index)(input_data)\n",
    "    X = LSTM(n_h ,return_sequences=False)(embedding_layer)\n",
    "    X = Dropout(dropout_prob)(X)\n",
    "    X = Dense(1)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "           \n",
    "    model = Model(inputs=input_data, outputs=X)\n",
    "    return model\n",
    "model = deepLSTM((MAX_LENGTH,), .5, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 135)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 135, 300)          919498200 \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 919,717,977\n",
      "Trainable params: 219,777\n",
      "Non-trainable params: 919,498,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=mean_squared_error,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.array([X_test.values[i][0] for i in range(len(X_test.values))])\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122500, 135)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122500 samples, validate on 52500 samples\n",
      "Epoch 1/100\n",
      "122500/122500 [==============================] - 386s 3ms/step - loss: 1318.9156 - accuracy: 0.0252 - val_loss: 1292.1524 - val_accuracy: 0.0400\n",
      "Epoch 2/100\n",
      "122500/122500 [==============================] - 411s 3ms/step - loss: 1182.7583 - accuracy: 0.0291 - val_loss: 1185.8269 - val_accuracy: 0.0256\n",
      "Epoch 3/100\n",
      "122500/122500 [==============================] - 447s 4ms/step - loss: 1127.3442 - accuracy: 0.0296 - val_loss: 1133.2685 - val_accuracy: 0.0335\n",
      "Epoch 4/100\n",
      "122500/122500 [==============================] - 436s 4ms/step - loss: 1085.6768 - accuracy: 0.0310 - val_loss: 1139.0253 - val_accuracy: 0.0369\n",
      "Epoch 5/100\n",
      "122500/122500 [==============================] - 463s 4ms/step - loss: 1036.8334 - accuracy: 0.0320 - val_loss: 1100.5682 - val_accuracy: 0.0301\n",
      "Epoch 6/100\n",
      "122500/122500 [==============================] - 421s 3ms/step - loss: 1000.2141 - accuracy: 0.0319 - val_loss: 1077.3563 - val_accuracy: 0.0385\n",
      "Epoch 7/100\n",
      "122500/122500 [==============================] - 382s 3ms/step - loss: 959.9986 - accuracy: 0.0317 - val_loss: 1046.0388 - val_accuracy: 0.0370\n",
      "Epoch 8/100\n",
      "122500/122500 [==============================] - 410s 3ms/step - loss: 926.5526 - accuracy: 0.0325 - val_loss: 1073.6064 - val_accuracy: 0.0342\n",
      "Epoch 9/100\n",
      "122500/122500 [==============================] - 1256s 10ms/step - loss: 883.0657 - accuracy: 0.0318 - val_loss: 1033.6896 - val_accuracy: 0.0342\n",
      "Epoch 10/100\n",
      "122500/122500 [==============================] - 389s 3ms/step - loss: 845.8800 - accuracy: 0.0331 - val_loss: 1027.3127 - val_accuracy: 0.0340\n",
      "Epoch 11/100\n",
      "122500/122500 [==============================] - 418s 3ms/step - loss: 816.5439 - accuracy: 0.0321 - val_loss: 1013.9757 - val_accuracy: 0.0333\n",
      "Epoch 12/100\n",
      "122500/122500 [==============================] - 424s 3ms/step - loss: 783.2819 - accuracy: 0.0324 - val_loss: 978.5151 - val_accuracy: 0.0312\n",
      "Epoch 13/100\n",
      "122500/122500 [==============================] - 434s 4ms/step - loss: 761.1705 - accuracy: 0.0337 - val_loss: 997.8836 - val_accuracy: 0.0309\n",
      "Epoch 14/100\n",
      "122500/122500 [==============================] - 442s 4ms/step - loss: 730.7336 - accuracy: 0.0340 - val_loss: 989.9876 - val_accuracy: 0.0365\n",
      "Epoch 15/100\n",
      "122500/122500 [==============================] - 442s 4ms/step - loss: 711.2000 - accuracy: 0.0335 - val_loss: 969.5198 - val_accuracy: 0.0363\n",
      "Epoch 16/100\n",
      "122500/122500 [==============================] - 391s 3ms/step - loss: 693.9548 - accuracy: 0.0333 - val_loss: 961.5139 - val_accuracy: 0.0338\n",
      "Epoch 17/100\n",
      "122500/122500 [==============================] - 639s 5ms/step - loss: 671.2940 - accuracy: 0.0341 - val_loss: 959.3701 - val_accuracy: 0.0355\n",
      "Epoch 18/100\n",
      "122500/122500 [==============================] - 830s 7ms/step - loss: 650.7404 - accuracy: 0.0336 - val_loss: 940.7091 - val_accuracy: 0.0330\n",
      "Epoch 19/100\n",
      "122500/122500 [==============================] - 610s 5ms/step - loss: 644.0217 - accuracy: 0.0343 - val_loss: 970.8697 - val_accuracy: 0.0346\n",
      "Epoch 20/100\n",
      "122500/122500 [==============================] - 427s 3ms/step - loss: 636.4869 - accuracy: 0.0340 - val_loss: 951.0311 - val_accuracy: 0.0353\n",
      "Epoch 21/100\n",
      "122500/122500 [==============================] - 630s 5ms/step - loss: 607.5654 - accuracy: 0.0344 - val_loss: 958.7273 - val_accuracy: 0.0354\n",
      "Epoch 22/100\n",
      "122500/122500 [==============================] - 918s 7ms/step - loss: 606.4754 - accuracy: 0.0338 - val_loss: 970.4957 - val_accuracy: 0.0350\n",
      "Epoch 23/100\n",
      "122500/122500 [==============================] - 435s 4ms/step - loss: 581.7202 - accuracy: 0.0345 - val_loss: 941.1934 - val_accuracy: 0.0339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb9a17b4fd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32,validation_data=(X_test, y_test),shuffle=True,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm_encoder.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03485714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, np.int64(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30.678875651250603\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[:3].predict\n",
    "model2 = Model(input = model.layers[0].input, output = model.layers[2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0].shape)\n",
    "model2.predict(X_test[0].reshape(1,135))\n",
    "from keras.models import load_model\n",
    "model3 = load_model(\"lstm_encoder.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.16738731e-01, -9.55399632e-01,  0.00000000e+00,\n",
       "         1.99299660e-02, -2.46438924e-02,  1.03284456e-01,\n",
       "         1.00000000e+00, -1.00000000e+00, -4.35456680e-03,\n",
       "        -0.00000000e+00,  9.99991119e-01,  0.00000000e+00,\n",
       "        -8.23505130e-03, -0.00000000e+00, -8.96549225e-03,\n",
       "         0.00000000e+00,  1.44540556e-02, -9.04576898e-01,\n",
       "         0.00000000e+00, -9.99999642e-01,  0.00000000e+00,\n",
       "        -3.59902173e-01, -6.42023422e-03,  0.00000000e+00,\n",
       "         0.00000000e+00, -6.96942559e-04, -0.00000000e+00,\n",
       "         0.00000000e+00, -3.53964090e-01, -0.00000000e+00,\n",
       "         6.49516296e-04, -6.43325318e-03, -1.24359988e-01,\n",
       "         3.98159027e-05,  0.00000000e+00,  1.49011598e-07,\n",
       "         0.00000000e+00, -7.61594772e-01,  0.00000000e+00,\n",
       "        -3.33819372e-09, -3.72914542e-07, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  9.50954735e-01,\n",
       "         7.19632983e-01, -1.67262151e-08, -1.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -7.61602581e-01,\n",
       "        -9.99999523e-01,  5.02384128e-03, -1.04294120e-08,\n",
       "         8.78241903e-04,  1.53362751e-04,  7.61498213e-01,\n",
       "        -4.23356928e-02,  0.00000000e+00,  5.66244125e-07,\n",
       "         9.60026145e-01, -1.00000000e+00,  1.00000000e+00,\n",
       "        -1.00000000e+00, -2.11116322e-03,  0.00000000e+00,\n",
       "         1.11143840e-02,  5.73119149e-02, -7.26484507e-02,\n",
       "        -4.57877703e-02,  0.00000000e+00, -1.39537646e-04,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  5.96046448e-08, -0.00000000e+00,\n",
       "        -1.85072422e-05,  0.00000000e+00,  4.76837101e-07,\n",
       "        -7.61594176e-01,  9.99999940e-01, -6.27511367e-02,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.84415560e-32,\n",
       "         5.65162145e-06, -1.85661629e-05, -0.00000000e+00,\n",
       "         0.00000000e+00, -1.62478932e-03,  1.93553057e-03,\n",
       "         0.00000000e+00, -1.00000000e+00,  3.30723226e-01,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.47527769e-01,  1.59938633e-02,  1.61570143e-02,\n",
       "        -0.00000000e+00, -9.99828875e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.61681199e-01,\n",
       "        -3.57627869e-07,  1.16136732e-06,  1.48951993e-04,\n",
       "         1.00000000e+00,  8.98761101e-08, -0.00000000e+00,\n",
       "         3.33654024e-02, -2.60660667e-02, -1.02919862e-02,\n",
       "         8.55326653e-05,  6.66899665e-04, -1.00000000e+00,\n",
       "        -1.00000000e+00,  1.19209290e-07,  1.00000000e+00,\n",
       "         0.00000000e+00, -1.19210043e-07]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(X_test[0].reshape(1,135))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Model(input = model.layers[0].input, output = model.layers[2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.16738731e-01, -9.55399632e-01,  0.00000000e+00,\n",
       "         1.99299660e-02, -2.46438924e-02,  1.03284456e-01,\n",
       "         1.00000000e+00, -1.00000000e+00, -4.35456680e-03,\n",
       "        -0.00000000e+00,  9.99991119e-01,  0.00000000e+00,\n",
       "        -8.23505130e-03, -0.00000000e+00, -8.96549225e-03,\n",
       "         0.00000000e+00,  1.44540556e-02, -9.04576898e-01,\n",
       "         0.00000000e+00, -9.99999642e-01,  0.00000000e+00,\n",
       "        -3.59902173e-01, -6.42023422e-03,  0.00000000e+00,\n",
       "         0.00000000e+00, -6.96942559e-04, -0.00000000e+00,\n",
       "         0.00000000e+00, -3.53964090e-01, -0.00000000e+00,\n",
       "         6.49516296e-04, -6.43325318e-03, -1.24359988e-01,\n",
       "         3.98159027e-05,  0.00000000e+00,  1.49011598e-07,\n",
       "         0.00000000e+00, -7.61594772e-01,  0.00000000e+00,\n",
       "        -3.33819372e-09, -3.72914542e-07, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  9.50954735e-01,\n",
       "         7.19632983e-01, -1.67262151e-08, -1.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -7.61602581e-01,\n",
       "        -9.99999523e-01,  5.02384128e-03, -1.04294120e-08,\n",
       "         8.78241903e-04,  1.53362751e-04,  7.61498213e-01,\n",
       "        -4.23356928e-02,  0.00000000e+00,  5.66244125e-07,\n",
       "         9.60026145e-01, -1.00000000e+00,  1.00000000e+00,\n",
       "        -1.00000000e+00, -2.11116322e-03,  0.00000000e+00,\n",
       "         1.11143840e-02,  5.73119149e-02, -7.26484507e-02,\n",
       "        -4.57877703e-02,  0.00000000e+00, -1.39537646e-04,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  5.96046448e-08, -0.00000000e+00,\n",
       "        -1.85072422e-05,  0.00000000e+00,  4.76837101e-07,\n",
       "        -7.61594176e-01,  9.99999940e-01, -6.27511367e-02,\n",
       "         0.00000000e+00,  0.00000000e+00, -2.84415560e-32,\n",
       "         5.65162145e-06, -1.85661629e-05, -0.00000000e+00,\n",
       "         0.00000000e+00, -1.62478932e-03,  1.93553057e-03,\n",
       "         0.00000000e+00, -1.00000000e+00,  3.30723226e-01,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.47527769e-01,  1.59938633e-02,  1.61570143e-02,\n",
       "        -0.00000000e+00, -9.99828875e-01,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.61681199e-01,\n",
       "        -3.57627869e-07,  1.16136732e-06,  1.48951993e-04,\n",
       "         1.00000000e+00,  8.98761101e-08, -0.00000000e+00,\n",
       "         3.33654024e-02, -2.60660667e-02, -1.02919862e-02,\n",
       "         8.55326653e-05,  6.66899665e-04, -1.00000000e+00,\n",
       "        -1.00000000e+00,  1.19209290e-07,  1.00000000e+00,\n",
       "         0.00000000e+00, -1.19210043e-07]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.predict(X_test[0].reshape(1,135))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
